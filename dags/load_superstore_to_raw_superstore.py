"""
DAG: superstore_etl
ÐžÐ¿Ð¸ÑÐ°Ð½Ð¸Ðµ: 
    Ð˜Ð½ÐºÑ€ÐµÐ¼ÐµÐ½Ñ‚Ð°Ð»ÑŒÐ½Ð°Ñ Ð·Ð°Ð³Ñ€ÑƒÐ·ÐºÐ° Ð´Ð°Ð½Ð½Ñ‹Ñ… Ð¸Ð· CSV Ð² PostgreSQL (ÑÐ»Ð¾Ð¹ raw),
    Ð·Ð°Ñ‚ÐµÐ¼ Ð·Ð°Ð¿ÑƒÑÐº dbt-Ñ‚Ñ€Ð°Ð½ÑÑ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸Ð¹ Ð¸ Ñ‚ÐµÑÑ‚Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ðµ ÐºÐ°Ñ‡ÐµÑÑ‚Ð²Ð° Ð´Ð°Ð½Ð½Ñ‹Ñ….
Ð¢ÐµÐ³Ð¸: superstore, etl, bronze-silver-gold
"""

from datetime import datetime
import pandas as pd
import psycopg2
from psycopg2.extras import execute_values

from airflow import DAG
from airflow.operators.python import PythonOperator
from airflow.operators.bash import BashOperator

# ============================================
# 1. ÐšÐžÐÐ¡Ð¢ÐÐÐ¢Ð« Ð˜ ÐÐÐ¡Ð¢Ð ÐžÐ™ÐšÐ˜
# ============================================

CSV_PATH = "/opt/airflow/data/raw/csv/superstore.csv"

# ÐŸÐ°Ñ€Ð°Ð¼ÐµÑ‚Ñ€Ñ‹ Ð¿Ð¾Ð´ÐºÐ»ÑŽÑ‡ÐµÐ½Ð¸Ñ Ðº PostgreSQL (Ñ†ÐµÐ»ÐµÐ²Ð°Ñ Ð±Ð°Ð·Ð° â€” dwh_raw)
PG_HOST = "postgres"
PG_DB = "dwh_raw"
PG_USER = "airflow"
PG_PASSWORD = "airflow"
TABLE_NAME = "raw.superstore_raw"

# ============================================
# 2. Ð¤Ð£ÐÐšÐ¦Ð˜Ð¯ Ð—ÐÐ“Ð Ð£Ð—ÐšÐ˜ Ð”ÐÐÐÐ«Ð¥ (BRONZE-Ð¡Ð›ÐžÐ™)
# ============================================

def load_superstore_to_raw():
    """
    Ð˜Ð½ÐºÑ€ÐµÐ¼ÐµÐ½Ñ‚Ð°Ð»ÑŒÐ½Ð°Ñ Ð·Ð°Ð³Ñ€ÑƒÐ·ÐºÐ° Ð´Ð°Ð½Ð½Ñ‹Ñ… Ð¸Ð· CSV Ð² Ñ‚Ð°Ð±Ð»Ð¸Ñ†Ñƒ raw.superstore_raw.
    - Ð¡Ð¾Ð·Ð´Ð°Ñ‘Ñ‚ ÑÑ…ÐµÐ¼Ñƒ raw, ÐµÑÐ»Ð¸ Ð½Ðµ ÑÑƒÑ‰ÐµÑÑ‚Ð²ÑƒÐµÑ‚.
    - Ð¡Ð¾Ð·Ð´Ð°Ñ‘Ñ‚ Ñ‚Ð°Ð±Ð»Ð¸Ñ†Ñƒ, ÐµÑÐ»Ð¸ Ð½Ðµ ÑÑƒÑ‰ÐµÑÑ‚Ð²ÑƒÐµÑ‚ (Ð²ÑÐµ ÐºÐ¾Ð»Ð¾Ð½ÐºÐ¸ Ñ‚Ð¸Ð¿Ð° text).
    - Ð—Ð°Ð³Ñ€ÑƒÐ¶Ð°ÐµÑ‚ Ñ‚Ð¾Ð»ÑŒÐºÐ¾ Ð½Ð¾Ð²Ñ‹Ðµ Ð·Ð°Ð¿Ð¸ÑÐ¸ Ð½Ð° Ð¾ÑÐ½Ð¾Ð²Ðµ Ð¼Ð°ÐºÑÐ¸Ð¼Ð°Ð»ÑŒÐ½Ð¾Ð¹ Ð´Ð°Ñ‚Ñ‹ Ð·Ð°ÐºÐ°Ð·Ð°.
    """
    
    # Ð§Ñ‚ÐµÐ½Ð¸Ðµ CSV-Ñ„Ð°Ð¹Ð»Ð°
    df = pd.read_csv(CSV_PATH, encoding="cp1251")
    
    if df.empty:
        print("âš ï¸  Ð¤Ð°Ð¹Ð» superstore.csv Ð¿ÑƒÑÑ‚. Ð—Ð°Ð³Ñ€ÑƒÐ·ÐºÐ° Ð¾Ñ‚Ð¼ÐµÐ½ÐµÐ½Ð°.")
        return
    
    columns = list(df.columns)
    
    # ÐŸÐ¾Ð´ÐºÐ»ÑŽÑ‡ÐµÐ½Ð¸Ðµ Ðº PostgreSQL
    conn = psycopg2.connect(
        host=PG_HOST,
        dbname=PG_DB,
        user=PG_USER,
        password=PG_PASSWORD,
    )
    conn.autocommit = True
    cur = conn.cursor()
    
    # Ð¡Ð¾Ð·Ð´Ð°Ð½Ð¸Ðµ ÑÑ…ÐµÐ¼Ñ‹ raw, ÐµÑÐ»Ð¸ Ð¾Ñ‚ÑÑƒÑ‚ÑÑ‚Ð²ÑƒÐµÑ‚
    cur.execute("CREATE SCHEMA IF NOT EXISTS raw;")
    
    # Ð¡Ð¾Ð·Ð´Ð°Ð½Ð¸Ðµ Ñ‚Ð°Ð±Ð»Ð¸Ñ†Ñ‹ Ñ Ð´Ð¸Ð½Ð°Ð¼Ð¸Ñ‡ÐµÑÐºÐ¸Ð¼Ð¸ ÐºÐ¾Ð»Ð¾Ð½ÐºÐ°Ð¼Ð¸ Ñ‚Ð¸Ð¿Ð° text
    columns_ddl = ",\n    ".join([f'"{col}" text' for col in columns])
    create_table_sql = f'''
    CREATE TABLE IF NOT EXISTS {TABLE_NAME} (
        {columns_ddl}
    );
    '''
    cur.execute(create_table_sql)
    
    # ÐžÐ¿Ñ€ÐµÐ´ÐµÐ»ÐµÐ½Ð¸Ðµ Ð¿Ð¾ÑÐ»ÐµÐ´Ð½ÐµÐ¹ Ð·Ð°Ð³Ñ€ÑƒÐ¶ÐµÐ½Ð½Ð¾Ð¹ Ð´Ð°Ñ‚Ñ‹
    cur.execute(f'SELECT MAX("Order_Date") FROM {TABLE_NAME}')
    last_date_result = cur.fetchone()[0]
    
    # ÐŸÑ€ÐµÐ¾Ð±Ñ€Ð°Ð·Ð¾Ð²Ð°Ð½Ð¸Ðµ ÐºÐ¾Ð»Ð¾Ð½ÐºÐ¸ Order_Date Ð² datetime
    df['Order_Date'] = pd.to_datetime(df['Order_Date'], format='%d/%m/%Y')
    
    if last_date_result:
        last_date = pd.to_datetime(last_date_result)
        new_data = df[df['Order_Date'] > last_date]
        print(f"ðŸ“… ÐŸÐ¾ÑÐ»ÐµÐ´Ð½ÑÑ Ð·Ð°Ð³Ñ€ÑƒÐ¶ÐµÐ½Ð½Ð°Ñ Ð´Ð°Ñ‚Ð°: {last_date}")
        print(f"âž• ÐÐ°Ð¹Ð´ÐµÐ½Ð¾ Ð½Ð¾Ð²Ñ‹Ñ… Ð·Ð°Ð¿Ð¸ÑÐµÐ¹: {len(new_data)}")
    else:
        new_data = df
        print("ðŸ†• ÐŸÐµÑ€Ð²Ð°Ñ Ð·Ð°Ð³Ñ€ÑƒÐ·ÐºÐ° â€” Ð¿ÐµÑ€ÐµÐ½Ð¾ÑÐ¸Ð¼ Ð²ÑÐµ Ð´Ð°Ð½Ð½Ñ‹Ðµ.")
    
    # Ð’ÑÑ‚Ð°Ð²ÐºÐ° Ñ‚Ð¾Ð»ÑŒÐºÐ¾ Ð½Ð¾Ð²Ñ‹Ñ… ÑÑ‚Ñ€Ð¾Ðº
    if not new_data.empty:
        rows = list(new_data.itertuples(index=False, name=None))
        insert_columns = ", ".join([f'"{col}"' for col in columns])
        insert_sql = f"INSERT INTO {TABLE_NAME} ({insert_columns}) VALUES %s"
        execute_values(cur, insert_sql, rows)
        print(f"âœ… Ð£ÑÐ¿ÐµÑˆÐ½Ð¾ Ð´Ð¾Ð±Ð°Ð²Ð»ÐµÐ½Ð¾ ÑÑ‚Ñ€Ð¾Ðº: {len(rows)}")
    else:
        print("â¸ï¸  ÐÐµÑ‚ Ð½Ð¾Ð²Ñ‹Ñ… Ð´Ð°Ð½Ð½Ñ‹Ñ… Ð´Ð»Ñ Ð·Ð°Ð³Ñ€ÑƒÐ·ÐºÐ¸.")
    
    cur.close()
    conn.close()

# ============================================
# 3. ÐžÐŸÐ Ð•Ð”Ð•Ð›Ð•ÐÐ˜Ð• DAG
# ============================================

with DAG(
    dag_id="superstore_etl",
    start_date=datetime(2025, 1, 1),
    schedule_interval=None,  # Ð¢Ð¾Ð»ÑŒÐºÐ¾ Ñ€ÑƒÑ‡Ð½Ð¾Ð¹ Ð·Ð°Ð¿ÑƒÑÐº
    catchup=False,
    tags=["superstore", "etl", "dbt"],
    description="Ð—Ð°Ð³Ñ€ÑƒÐ·ÐºÐ° Superstore â†’ raw â†’ dbt (silver/gold) â†’ Ñ‚ÐµÑÑ‚Ñ‹",
    doc_md=__doc__,  # ÐŸÐ¾Ð´Ñ‚ÑÐ³Ð¸Ð²Ð°ÐµÑ‚ Ð´Ð¾ÐºÑÑ‚Ñ€Ð¸Ð½Ð³ Ð¸Ð· Ð½Ð°Ñ‡Ð°Ð»Ð° Ñ„Ð°Ð¹Ð»Ð°
) as dag:

    # ============================================
    # 4. Ð—ÐÐ”ÐÐ§Ð˜ (TASKS)
    # ============================================
    
    # Ð—Ð°Ð´Ð°Ñ‡Ð° 1: Ð—Ð°Ð³Ñ€ÑƒÐ·ÐºÐ° Ð´Ð°Ð½Ð½Ñ‹Ñ… Ð² ÑÐ»Ð¾Ð¹ raw (Ð¸Ð½ÐºÑ€ÐµÐ¼ÐµÐ½Ñ‚Ð°Ð»ÑŒÐ½Ð¾)
    load_to_bronze = PythonOperator(
        task_id="load_to_bronze",
        python_callable=load_superstore_to_raw,
        doc="Ð˜Ð½ÐºÑ€ÐµÐ¼ÐµÐ½Ñ‚Ð°Ð»ÑŒÐ½Ð°Ñ Ð·Ð°Ð³Ñ€ÑƒÐ·ÐºÐ° CSV Ð² raw.superstore_raw",
    )
    
    # Ð—Ð°Ð´Ð°Ñ‡Ð° 2: Ð—Ð°Ð¿ÑƒÑÐº dbt-Ñ‚Ñ€Ð°Ð½ÑÑ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸Ð¹ (ÑÐ±Ð¾Ñ€ÐºÐ° silver Ð¸ gold)
    dbt_run = BashOperator(
        task_id="run_dbt_transformations",
        bash_command="cd /opt/airflow/dbt && dbt run",
        doc="Ð—Ð°Ð¿ÑƒÑÐº Ð¼Ð¾Ð´ÐµÐ»ÐµÐ¹ dbt: ÑÐµÑ€ÐµÐ±Ñ€Ð¾ Ð¸ Ð·Ð¾Ð»Ð¾Ñ‚Ð¾",
    )
    
    # Ð—Ð°Ð´Ð°Ñ‡Ð° 3: Ð—Ð°Ð¿ÑƒÑÐº Ñ‚ÐµÑÑ‚Ð¾Ð² ÐºÐ°Ñ‡ÐµÑÑ‚Ð²Ð° Ð´Ð°Ð½Ð½Ñ‹Ñ… (dbt test)
    dbt_test = BashOperator(
        task_id="test_data_quality",
        bash_command="cd /opt/airflow/dbt && dbt test",
        doc="ÐŸÑ€Ð¾Ð²ÐµÑ€ÐºÐ° Ñ†ÐµÐ»Ð¾ÑÑ‚Ð½Ð¾ÑÑ‚Ð¸ Ð¸ ÐºÐ°Ñ‡ÐµÑÑ‚Ð²Ð° Ð´Ð°Ð½Ð½Ñ‹Ñ… Ñ‡ÐµÑ€ÐµÐ· dbt-Ñ‚ÐµÑÑ‚Ñ‹",
    )
    
    # ============================================
    # 5. ÐŸÐžÐ Ð¯Ð”ÐžÐš Ð’Ð«ÐŸÐžÐ›ÐÐ•ÐÐ˜Ð¯ (DEPENDENCIES)
    # ============================================
    
    load_to_bronze >> dbt_run >> dbt_test